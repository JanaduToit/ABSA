{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jduto\\AppData\\Local\\anaconda3\\envs\\Master\\lib\\site-packages\\google\\rpc\\__init__.py:20: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.rpc')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  pkg_resources.declare_namespace(__name__)\n",
      "c:\\Users\\jduto\\AppData\\Local\\anaconda3\\envs\\Master\\lib\\site-packages\\pkg_resources\\__init__.py:2350: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
      "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
      "  declare_namespace(parent)\n",
      "C:\\Users\\jduto\\AppData\\Local\\Temp\\ipykernel_13244\\1321584916.py:155: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  s['clean_text'] = s.apply(preprocess_text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 1308\n",
      "Total Vocabulary Size: 1308\n",
      "Total Vocabulary Size: 1308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jduto\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set()\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer, ToktokTokenizer\n",
    "import re\n",
    "from nltk import pos_tag\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import os\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import spacy\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import re\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "res = pd.read_csv(r\"C:\\Users\\jduto\\OneDrive\\Documents\\Meesters\\Coding\\Restaurants_Train_v2.csv\")\n",
    "s = res['Sentence']\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = word_tokenize\n",
    "custom_spellchecker = SpellChecker()\n",
    "\n",
    "# Contractions dictionary\n",
    "contractions_dict = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i had\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it had\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"she'd\": \"she had\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they had\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"we'd\": \"we had\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"you'd\": \"you had\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\",\n",
    "    \"ambience\" : \"ambiance\",\n",
    "    \"waitress\" : \"waiter\",\n",
    "    \"hostess\" : \"host\"\n",
    "}\n",
    "\n",
    "contractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))\n",
    "\n",
    "\n",
    "def expand_contractions(text, contractions_dict=contractions_dict):\n",
    "    def replace(match):\n",
    "        return contractions_dict[match.group(0)]\n",
    "\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern = r'[^a-zA-Z0-9\\s]' if not remove_digits else r'[^a-zA-Z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = tokenizer(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "    return lemmatized_text\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = expand_contractions(text)\n",
    "    text = remove_special_characters(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize_text(text)\n",
    "    return text\n",
    "s['clean_text'] = s.apply(preprocess_text)\n",
    "# Function to perform spell correction\n",
    "def spell_correction(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = custom_spellchecker.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_word = custom_spellchecker.correction(word)\n",
    "            if corrected_word is not None:\n",
    "                corrected_text.append(corrected_word)\n",
    "            else:\n",
    "                corrected_text.append(word)\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return ' '.join(corrected_text)\n",
    "\n",
    "# Apply spell correction to the cleaned text\n",
    "s['clean_text'] =s['clean_text'].apply(spell_correction)\n",
    "\n",
    "data = list(s['clean_text'])\n",
    "bigram = gensim.models.Phrases(data, min_count=20, threshold=100) \n",
    "trigram = gensim.models.Phrases(bigram[data], threshold=100)  \n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "f = [\"friend\",\"list\",\"man\",\"woman\",\"husband\",\"wife\",\"boyfriend\",\"girlfriend\",\"sake\",'lot',\"way\",\"choice\",\"minute\",\"def\",\"stuff\",\"fact\",\"app\",\"bet\",\"thing\"]\n",
    "stop_words = nltk.corpus.stopwords.words('english') \n",
    "def process_words(texts, stop_words=stop_words, allowed_tags=['NOUN']):\n",
    "    \n",
    "    \"\"\"Convert a document into a list of lowercase tokens, build bigrams-trigrams, implement lemmatization\"\"\"\n",
    "    \n",
    "    # remove stopwords, short tokens and letter accents \n",
    "    texts = [[word for word in simple_preprocess(str(doc), deacc=True, min_len=3) if word not in stop_words] for doc in texts]\n",
    "    \n",
    "    # bi-gram and tri-gram implementation\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    \n",
    "    texts_out = []\n",
    "\n",
    "    # implement lemmatization and filter out unwanted part of speech tags\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_tags])\n",
    "    \n",
    "    # remove stopwords and short tokens again after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc), deacc=True, min_len=3) if word not in stop_words] for doc in texts_out]    \n",
    "    \n",
    "    return texts_out\n",
    "     \n",
    "    \n",
    "data_ready = process_words(data)  \n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "print('Total Vocabulary Size:', len(id2word))\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "dict_corpus = {}\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "  for idx, freq in corpus[i]:\n",
    "    if id2word[idx] in dict_corpus:\n",
    "      dict_corpus[id2word[idx]] += freq\n",
    "    else:\n",
    "       dict_corpus[id2word[idx]] = freq\n",
    "\n",
    "    \n",
    "dict_df = pd.DataFrame.from_dict(dict_corpus, orient='index', columns=['freq'])\n",
    "#extension = dict_df[dict_df.freq<5].index.tolist()\n",
    "#stop_words.extend(extension)\n",
    "\n",
    "data_ready = process_words(data)\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "print('Total Vocabulary Size:', len(id2word))\n",
    "     \n",
    "# Filter out words that occur less than 10 documents, or more than 50% of the documents.\n",
    "\n",
    "#id2word.filter_extremes(no_below=10, no_above=0.8)\n",
    "\n",
    "print('Total Vocabulary Size:', len(id2word))\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "\n",
    "# Specify the path to the Mallet binary\n",
    "\n",
    "# Train the LDA model using LdaModel with MalletCorpus\n",
    "ldamodel = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=id2word,\n",
    "    num_topics=100\n",
    ")\n",
    "\n",
    "words = list(id2word.values())\n",
    "nums = list(id2word.keys())\n",
    "stacked = s['clean_text']\n",
    "big_list_of_sentence_topics = []\n",
    "for i in stacked.T:\n",
    "    sentence_topics = []\n",
    "    tokens = i.split()\n",
    "    for k in tokens:\n",
    "        if k in stop_words : continue\n",
    "        try:\n",
    "            position = words.index(k)\n",
    "            key = nums[position]\n",
    "            sentence_topics.append(key)\n",
    "        except ValueError: continue\n",
    "    big_list_of_sentence_topics.append(sentence_topics)\n",
    "\n",
    "test_sentence = big_list_of_sentence_topics[1]\n",
    "for i in test_sentence:\n",
    "    words = nums.index(i)\n",
    "def get_sentence_topics(sentence):\n",
    "    topic_list = []\n",
    "    for i in sentence:\n",
    "        topic_prob = ldamodel.get_term_topics(word_id=i, minimum_probability = 0.0)\n",
    "        topic_list.append(topic_prob)\n",
    "    return topic_list\n",
    "obj = get_sentence_topics(big_list_of_sentence_topics[1])\n",
    "test_df = pd.DataFrame(obj)\n",
    "test_df = pd.DataFrame(test_df.stack())\n",
    "index_list = []\n",
    "for i in range(len(test_df)):\n",
    "    counter = i\n",
    "    index_list.append(counter)\n",
    "    counter+=1\n",
    "#print (index_list)\n",
    "test_df.index = index_list\n",
    "\n",
    "def predict_top_topic(obj):\n",
    "    temp_df = pd.DataFrame(obj)\n",
    "    temp_df = temp_df.stack()\n",
    "    categories_list = []\n",
    "    prob_list = []\n",
    "    index_list = []\n",
    "    for i in range(len(temp_df)):\n",
    "        counter = i\n",
    "        index_list.append(counter)\n",
    "        counter+=1\n",
    "    temp_df.index = index_list\n",
    "    for i in temp_df.T:\n",
    "        categories_list.append(i[0])\n",
    "        prob_list.append(i[1])\n",
    "    categories_df = pd.DataFrame(categories_list)\n",
    "    col_name = ['cat']\n",
    "    categories_df.columns = col_name\n",
    "    categories_df['probs'] = pd.DataFrame(prob_list)\n",
    "    categories_df = categories_df.groupby(['cat']).sum()\n",
    "    top = categories_df.sort_values(by=['probs'], ascending = False)\n",
    "    top = top.head(1).index[0]\n",
    "    return top\n",
    "\n",
    "err_list = []\n",
    "pred_list = []\n",
    "for i in range(len(big_list_of_sentence_topics)):\n",
    "    obj = get_sentence_topics(big_list_of_sentence_topics[i])\n",
    "    try:\n",
    "        pred = predict_top_topic(obj)\n",
    "        pred_list.append(pred)\n",
    "    except ValueError:\n",
    "            err_list.append(big_list_of_sentence_topics[i])\n",
    "            #print('Error at position: ',i)\n",
    "            pred_list.append(999)\n",
    "\n",
    "pred_df = pd.DataFrame(pred_list)\n",
    "counts = pred_df.groupby(0).sum()\n",
    "col = ['topic']\n",
    "pred_df.columns = col\n",
    "\n",
    "a = {}\n",
    "num_clusters =100  # Adjust the number of clusters as needed\n",
    "for i in range(num_clusters):\n",
    "    a[i] = (stacked[pred_df.topic == i])\n",
    "    \n",
    "# Text Summarization\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Convert the sentences in a0 to a single string\n",
    "\n",
    "\n",
    "def generate_summary_from_text(text, top_n=5):\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Preprocess the sentences\n",
    "    sentences = [sentence.lower() for sentence in sentences]\n",
    "    sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    sentences = [[word for word in sentence if word.isalnum()] for sentence in sentences]\n",
    "    \n",
    "    # Remove stop words\n",
    "    sentences = [[word for word in sentence if word not in stop_words] for sentence in sentences]\n",
    "    \n",
    "    # Calculate sentence scores based on word frequencies\n",
    "    word_frequencies = {}\n",
    "    for sentence in sentences:\n",
    "        for word in sentence:\n",
    "            if word not in word_frequencies:\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    \n",
    "    # Normalize the word frequencies\n",
    "    maximum_frequency = max(word_frequencies.values())\n",
    "    for word in word_frequencies.keys():\n",
    "        word_frequencies[word] = word_frequencies[word] / maximum_frequency\n",
    "    \n",
    "    # Calculate sentence scores\n",
    "    sentence_scores = {}\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence_scores[i] = 0\n",
    "        for word in sentence:\n",
    "            if word in word_frequencies:\n",
    "                sentence_scores[i] += word_frequencies[word]\n",
    "    \n",
    "    # Sort the sentence scores and get the top N sentences\n",
    "    top_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:top_n]\n",
    "    top_sentences = [sentences[i] for i in top_sentences]\n",
    "    \n",
    "    # Flatten the top sentences and join them to form the summary\n",
    "    summary = \". \".join([\" \".join(sentence) for sentence in top_sentences])\n",
    "    \n",
    "    return summary\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def generate_one_word_summary_from_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Preprocess the sentences\n",
    "    preprocessed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence.lower())\n",
    "        tagged_words = pos_tag(words)  # Perform POS tagging\n",
    "        nouns = [word for word, pos in tagged_words if pos.startswith('N')]  # Retain only nouns\n",
    "        filtered_words = [word for word in nouns if word.isalnum() and word not in stop_words]\n",
    "        preprocessed_sentences.append(filtered_words)\n",
    "    \n",
    "    # Calculate sentence scores based on word frequencies\n",
    "    word_frequencies = {}\n",
    "    for sentence in preprocessed_sentences:\n",
    "        for word in sentence:\n",
    "            if word not in word_frequencies:\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1\n",
    "    \n",
    "    # Check if word_frequencies dictionary is empty\n",
    "    if not word_frequencies:\n",
    "        return None\n",
    "    \n",
    "    # Sort the word frequencies and select the most frequent word\n",
    "    top_word = max(word_frequencies, key=word_frequencies.get)\n",
    "    \n",
    "    return top_word\n",
    "\n",
    "# Iterate through a0_ to a9_ and generate one-word summaries\n",
    "summary = []\n",
    "for i in range(num_clusters):\n",
    "    set_name = a[i]\n",
    "    reviews_set = set_name \n",
    "    text = \". \".join(reviews_set)\n",
    "    summary.append(generate_one_word_summary_from_text(text))\n",
    "    \n",
    "topic_summary_map = {}\n",
    "\n",
    "# Iterate over the range of available summaries\n",
    "for i in range(min(len(summary), 100)):\n",
    "    topic_summary_map[i] = summary[i]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been exported to data_ready.txt\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path where you want to save the text file\n",
    "output_file_path = \"data_ready.txt\"\n",
    "\n",
    "# Open the file in write mode and write each processed document on a new line\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    for document in data_ready:\n",
    "        processed_text = \" \".join(document)  # Join the words in the document list\n",
    "        output_file.write(processed_text + \"\\n\")  # Write the processed text to the file\n",
    "\n",
    "print(\"Data has been exported to\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =pd.DataFrame(res['Sentence'])\n",
    "test['Aspect'] = res['Aspect Term']\n",
    "test['Aspect Pred'] = pred_df['topic'].map(topic_summary_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to perform lexicon-based sentiment analysis\n",
    "def perform_sentiment_analysis(text):\n",
    "    sentiment_score = sia.polarity_scores(text)\n",
    "    compound_score = sentiment_score['compound']\n",
    "    \n",
    "    if compound_score > 0:\n",
    "        return 'positive'\n",
    "    elif compound_score < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment analysis to the 'clean_text' column\n",
    "s['sentiment'] = s['clean_text'].apply(perform_sentiment_analysis)\n",
    "\n",
    "test['polarity'] = res['polarity']\n",
    "test['predicted_polarity'] = s['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7971838613593285\n",
      "Precision: 0.7900800328185226\n",
      "Recall: 0.7971838613593285\n",
      "F1-score: 0.7848975479934776\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(res['Sentence'], res['polarity'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert text into a numerical representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the sentiment analysis model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "X_vectorised = vectorizer.transform(res['Sentence'])\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_vectorised)\n",
    "\n",
    "# Decode the predicted labels\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "ytest = res['polarity']\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(ytest, y_pred_decoded)\n",
    "precision = precision_score(ytest, y_pred_decoded, average='weighted')\n",
    "recall = recall_score(ytest, y_pred_decoded, average='weighted')\n",
    "f1 = f1_score(ytest, y_pred_decoded, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['polarity'] = res['polarity']\n",
    "test['predicted_polarity'] = y_pred_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23422691578662333\n",
      "Precision: 0.008048237293117367\n",
      "Recall: 0.0189479056526578\n",
      "F1-score: 0.009604864946259718\n",
      "SENTIMENT:\n",
      "Accuracy: 0.7971838613593285\n",
      "Precision: 0.7601756934504733\n",
      "Recall: 0.5828866952191635\n",
      "F1-score: 0.6145919192812342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jduto\\AppData\\Local\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jduto\\AppData\\Local\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'true_labels' contains the true labels for the data\n",
    "true_labels = test['Aspect']\n",
    "\n",
    "# Assuming 'pred_df' contains the predicted topics for each sentence\n",
    "pred_labels = test['Aspect Pred'].astype(str)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(true_labels, pred_labels, average='macro')\n",
    "recall = recall_score(true_labels, pred_labels, average='macro')\n",
    "f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n",
    "\n",
    "print(\"SENTIMENT:\")\n",
    "true_labels = test['polarity'] \n",
    "# Assuming 'pred_df' contains the predicted topics for each sentence\n",
    "pred_labels = test['predicted_polarity']\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(true_labels, pred_labels, average='macro')\n",
    "recall = recall_score(true_labels, pred_labels, average='macro')\n",
    "f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5334190231362468\n",
      "Precision: 0.27595455872551666\n",
      "Recall: 0.21386050877587828\n",
      "F1-score: 0.21478087065335583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jduto\\AppData\\Local\\Temp\\ipykernel_10400\\3715440498.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_filter['Aspect Pred'] = test['Aspect Pred']\n",
      "c:\\Users\\jduto\\AppData\\Local\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\jduto\\AppData\\Local\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aspect_term_counts = test['Aspect'].apply(preprocess_text).str.lower().value_counts()\n",
    "\n",
    "top_aspect_terms = aspect_term_counts.head(50).index.tolist()\n",
    "# Filter the original DataFrame to include only rows with top aspect terms\n",
    "test_filter = pd.DataFrame(test)\n",
    "test_filter = test[test['Aspect'].isin(top_aspect_terms)]\n",
    "test_filter['Aspect Pred'] = test['Aspect Pred']\n",
    "\n",
    "# Assuming 'true_labels' contains the true labels for the data\n",
    "true_labels = test_filter['Aspect']\n",
    "\n",
    "# Assuming 'pred_df' contains the predicted topics for each sentence\n",
    "pred_labels = test_filter['Aspect Pred'].astype(str)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(true_labels, pred_labels, average='macro')\n",
    "recall = recall_score(true_labels, pred_labels, average='macro')\n",
    "f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7718508997429306\n",
      "Precision: 0.726582491325539\n",
      "Recall: 0.53990189622392\n",
      "F1-score: 0.5566340850577435\n"
     ]
    }
   ],
   "source": [
    "true_labels = test_filter['polarity']\n",
    "# Assuming 'pred_df' contains the predicted topics for each sentence\n",
    "pred_labels = test_filter['predicted_polarity']\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, pred_labels)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(true_labels, pred_labels, average='macro')\n",
    "recall = recall_score(true_labels, pred_labels, average='macro')\n",
    "f1 = f1_score(true_labels, pred_labels, average='macro')\n",
    "\n",
    "# Print the performance metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'Aspect' and calculating polarity percentages\n",
    "grouped = test.groupby('Aspect Pred')['predicted_polarity'].value_counts(normalize=True).unstack().fillna(0) * 100\n",
    "grouped_correct = test.groupby('Aspect')['polarity'].value_counts(normalize=True).unstack().fillna(0) * 100\n",
    "# Reordering columns for better readability\n",
    "grouped = grouped[['negative', 'neutral', 'positive']]\n",
    "grouped_correct = grouped_correct[['negative', 'neutral', 'positive']]\n",
    "summary = pd.DataFrame(grouped)\n",
    "summary_c = pd.DataFrame(grouped_correct)\n",
    "summary.to_excel('summary_pred.xlsx')\n",
    "summary_c.to_excel('summary_correct.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7218614718614719\n",
      "Precision: 0.6912715775683084\n",
      "Recall: 0.7218614718614719\n",
      "F1-score: 0.7003538265684714\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(res['Sentence'], res['polarity'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert text into a numerical representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the sentiment analysis model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Decode the predicted labels\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred_decoded)\n",
    "precision = precision_score(y_test, y_pred_decoded, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_decoded, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_decoded, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7218614718614719\n",
      "Precision: 0.6912715775683084\n",
      "Recall: 0.7218614718614719\n",
      "F1-score: 0.7003538265684714\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(res['Sentence'], res['polarity'], test_size=0.25, random_state=42)\n",
    "\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert text into a numerical representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the sentiment analysis model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Decode the predicted labels\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred_decoded)\n",
    "precision = precision_score(y_test, y_pred_decoded, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_decoded, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_decoded, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9173986170809194\n",
      "Precision: 0.9061528407823294\n",
      "Recall: 0.9173986170809194\n",
      "F1-score: 0.9111622060047108\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(revi['Review'], revi['Sentiment'], test_size=0.2, random_state=42)\n",
    "# Encode the target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert text into a numerical representation\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the sentiment analysis model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train_encoded)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Decode the predicted labels\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred_decoded)\n",
    "precision = precision_score(y_test, y_pred_decoded, average='weighted')\n",
    "recall = recall_score(y_test, y_pred_decoded, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred_decoded, average='weighted')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the new dataset: 0.5778499864608719\n",
      "Precision on the new dataset: 0.5401115572561377\n",
      "Recall on the new dataset: 0.5778499864608719\n",
      "F1-score on the new dataset: 0.5573695962783218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jduto\\AppData\\Local\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#label_encoder = LabelEncoder()\n",
    "#label_encoder.fit(test['polarity'])\n",
    "\n",
    "# Preprocess the new dataset\n",
    "X_new = test['Sentence']\n",
    "y_new_encoded = test['polarity']\n",
    "\n",
    "# Convert text into a numerical representation\n",
    "X_new_vectorized = vectorizer.transform(X_new)\n",
    "\n",
    "# Make predictions on the new dataset\n",
    "y_new_pred = model.predict(X_new_vectorized)\n",
    "\n",
    "# Optionally, decode the predicted labels if necessary\n",
    "y_new_pred_decoded = label_encoder.inverse_transform(y_new_pred)\n",
    "\n",
    "# Evaluate the model's performance on the new dataset\n",
    "accuracy_new = accuracy_score(test['polarity'], y_new_pred_decoded)\n",
    "precision_new = precision_score(test['polarity'], y_new_pred_decoded, average='weighted')\n",
    "recall_new = recall_score(test['polarity'], y_new_pred_decoded, average='weighted')\n",
    "f1_new = f1_score(test['polarity'], y_new_pred_decoded, average='weighted')\n",
    "\n",
    "print(\"Accuracy on the new dataset:\", accuracy_new)\n",
    "print(\"Precision on the new dataset:\", precision_new)\n",
    "print(\"Recall on the new dataset:\", recall_new)\n",
    "print(\"F1-score on the new dataset:\", f1_new)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
